import json
import re
import os

from lxml import etree, builder
from datetime import datetime

class FeedParser:
    def __init__(self, json):
        self.E = builder.ElementMaker(nsmap={
            'atom':'http://www.w3.org/2005/Atom',
            'itunes': 'http://www.itunes.com/dtds/podcast-1.0.dtd',
            'content': 'http://purl.org/rss/1.0/modules/content/'
        })
        self.itunes = builder.ElementMaker(namespace='http://www.itunes.com/dtds/podcast-1.0.dtd')
        self.content = builder.ElementMaker(namespace='http://purl.org/rss/1.0/modules/content/')
        self.json = json

        self.build_feed()
        self.parse_items()

    def build_feed(self):
        self.rss = self.E.rss(
            self.E.channel(
                self._ele('title'),
                self._ele('link'),
                self._ele('pubDate'),
                self._ele('generator'),
                self._ele('language'),
                self._ele('description'),
                self._itunes_ele('author'),
                self.itunes.image(href=self.json['image']),
                self.E.webMaster(self.json['email']),
                self.E.ttl('60'),
                self.E.image(
                    self.E.url(self.json['image'])
                ),
                self._itunes_ele('type')
            )
        )


    def _ele(self, tag):
        return self.E(tag, self.json[tag])
    
    def _itunes_ele(self, tag):
        return self.itunes(tag, self.json[tag])

    def parse_items(self):
        channel = self.rss.xpath('//channel')[0]
        for i, item in enumerate(self.json['items']):
            episode = self.E.item(
                self.E.title(item['title']),
                self.E.link(item['link']),
                self.E.pubDate(item['pubDate']),
                self.E.guid(item['guid']),
                
                self.itunes.episodeType('full'),
                self.itunes.image(href=item['image']),
                self.E.enclosure(url=item['enclosure'], type="audio/mpeg"),
                self.itunes.duration(item['duration']),
                self.E.description(item['description']),
                self.content.encoded(etree.CDATA(item['description']))
            )
            channel.append(episode)

    def save(self, path):
        with open(path, 'wb+') as f:
            f.write(etree.tostring(self.rss, xml_declaration=True, encoding='UTF-8'))

class JsonParser:
    def __init__(self, path, other):
        if not os.path.isabs(path):
            path = os.path.join(os.path.dirname(__file__), path)
        with open(path)  as f:
            self._items = json.load(f)

        self._sort_items()
        self._complete_items(other)
        self._parse_shownotes()
        new_items = self._build_items()

        self._feed = {
            'title': 'åæ´¾å½±è¯„',
            'link': 'https://fanpaiyingping.com',
            'pubDate': format_time(self._items[-1]['pub_date']),
            'generator': 'python',
            'language': 'zh-cn',
            'description': 'è‹¥æ‰¹è¯„ä¸è‡ªç”±ï¼Œåˆ™èµç¾æ— æ„ä¹‰ã€‚å…šåŒä¼å¼‚ï¼ŒçŒ›äºç‚®ç«ã€‚',
            'author': 'æ³¢ç±³å’Œä»–çš„æœ‹å‹ä»¬',
            'image': 'https://raw.githubusercontent.com/Reyshawn/FanpieFilmFeed/master/fanPie/assets/939x0w.jpg',
            'name': 'reyshawn',
            'email': 'reshawnchang@gamil.com',
            'type': 'TV & Film',
            'items': new_items
        }

    # sort items by episode number
    def _sort_items(self):
        def cmp(i):
            return int(i['episode'][:3]), len(i['episode']), int(i['episode'][-1:])

        self._items.sort(key=cmp, reverse=True)
    
    # complete items by other rss file, mainly url, duration, image
    def _complete_items(self, path):
        incomp_url = {}
        incomp_dur = {}
        for i, item in enumerate(self._items):
            if item['url'] == 'âŒ':
                incomp_url[item['episode']] = i

            if item['duration'] == 'âŒ':
                incomp_dur[item['episode']] = i
        
        root = etree.parse(path)
        items = root.xpath('//item')

        for i in items:
            title = i.find('title').text
            if title[:3] in incomp_url.keys():
                url = i.find('enclosure').attrib['url']
                num = incomp_url[title[:3]]
                self._items[num]['url'] = url
            
            if title[:3] in incomp_dur.keys():
                dur = i.find('itunes:duration', namespaces=i.nsmap).text
                num = incomp_dur[title[:3]]
                self._items[num]['duration'] = dur

        self._items[incomp_dur['131 sep: 1']]['duration'] = '00:55:30'
        self._items[incomp_dur['085']]['duration'] = '02:00:00'
        self._items[incomp_dur['065 sep: 1']]['duration'] = '00:58:00'
        self._items[incomp_dur['048 sep: 1']]['duration'] = '01:09:36'

    def _parse_shownotes(self):
        def _format_scoring(s, hosts):
            patterns = [
                r'(ã€Š[^ã€‹]*?ã€‹([\(|ï¼ˆ][^\)]*?[\)|ï¼‰])?)(ç»¼åˆ)?(å¹³å‡)?æ€»?åˆ†æ•°?[ï¼š|:]çº¦?(?P<score>[0-9\.]*)åˆ†?',
                r'[(ç»¼åˆ)|(å¹³å‡)|æ€»]åˆ†æ•°?[ï¼š|:]çº¦?(?P<score>[0-9\.]*)åˆ†?'
            ]
            if s == 'âŒ':
                return s
            end_s = re.search(r'[(|ï¼ˆ]?éŸ³é¢‘åæœŸåˆ¶ä½œ', s)
            if end_s:
                end = '<p>' + s[end_s.span()[0]:] + '</p>'
                s = s[:end_s.span()[0]]
            else:
                end = ''

            if 'æ³¢ç±³' not in hosts:
                hosts.append('æ³¢ç±³')

            for pattern in patterns:
                ave = re.search(pattern, s)
                if ave and ave['score']:
                    s = re.sub(pattern, '', s)
                    break
                
            s = s.replace('&amp;', '&')
            s = s.replace('ï¼ˆä»¥ä¸‹å¹¿å‘Šï¼Œç”±å¾®ä¿¡å¹³å°è‡ªåŠ¨æ’å…¥ï¼Œæˆ‘ä»¬ç¼–è¾‘æ–‡ç« æ—¶çœ‹ä¸åˆ°å†…å®¹ï¼Œæ¯ä½è¯»è€…çœ‹åˆ°çš„ä¹Ÿå¹¶ä¸ç›¸åŒï¼‰', '')

            if not ave:
                print('exception:', s)

            pos = []
            for host in hosts:
                if s.find(host) > -1:
                    pos.append(s.find(host))

            pos.sort()
            try:
                st = pos[0]
            except:
                # print(item['episode'])
                return s
            res = []
            for i, p in enumerate(pos[1:]):
                res.append(s[st:p])
                st = p
            res.append(s[st:])
            res = ['<p>' + i + '</p>' for i in res]

            scoring = '\n'.join(res) + '\n' + end + '\n\n'
            return scoring + '<p>å¹³å‡åˆ†: ' + ave['score'] + '</p>' if ave else scoring

        def _format_outline(s):
            patterns = [
                r'((ç¬¬?[0-9]å°æ—¶)?ç¬¬?[0-9]{1,2}[ç§’|åˆ†]é’Ÿ?åŠ?-((ç¬¬?[0-9]å°æ—¶)?ç¬¬?[0-9]{1,2}åˆ†é’Ÿ?åŠ?)?(å°¾å£°)?)',
                r'([0-9]{2}:[0-9]{2}:[0-9]{2}-[0-9]{2}:[0-9]{2}:[0-9]{2})',
                r'([0-9][ï¼‰)ã€])',
                r'(å¼€åœºæ›²)',
                r'(ç»“æŸæ›²)',
                r'(å½±ç‰‡(ã€Š[^ã€‹]*?ã€‹)?(\([^\)]*?\))?(é‡è¦)?ä¿¡æ¯[^ç®€è¦ä»‹ç»])'
            ]
            for pattern in patterns:
                s = re.sub(pattern, r'\n\1', s)
            s = s.split('\n')
            s = ['<p>' + i +'</p>' for i in s]
            s = '\n'.join(s)
            s = s.replace('&amp;', '&')
            s = re.sub(r'(ä¸‹è½½å®Œæ•´èŠ‚ç›®)?(æ”¶å¬èŠ‚ç›®)?è¯·ç‚¹å‡»(æ–‡æœ«)?\"é˜…è¯»åŸæ–‡\"æŒ‰é’®ã€‚', '', s)
            s = s.replace('ï¼ˆä»¥ä¸‹å¹¿å‘Šï¼Œç”±å¾®ä¿¡å¹³å°è‡ªåŠ¨æ’å…¥ï¼Œæˆ‘ä»¬ç¼–è¾‘æ–‡ç« æ—¶çœ‹ä¸åˆ°å†…å®¹ï¼Œæ¯ä½è¯»è€…çœ‹åˆ°çš„ä¹Ÿå¹¶ä¸ç›¸åŒï¼‰', '')

            return s

        def _format_list(l):
            res = '<h2>æœ¬æœŸç‰‡ç›®</h2>\n<ul>\n'
            for i, item in enumerate(l):
                res += '<li>ã€' + item['name'] + 'ã€( ' + item['time'] + ' )</li>\n'
            return res + '</ul>\n'

        for i, item in enumerate(self._items):
            hosts = item['hosts']
            film = '<h1>ã€' + item['film'] + 'ã€</h1>\n\n'
            scoring = _format_scoring(item['shownotes']['film_scoring'], hosts)
            outline = _format_outline(item['shownotes']['film_outline'])
            f_list = _format_list(item['shownotes']['film_list'])
            summary = film + scoring + '\n\n' + outline + '\n\n' + f_list
            summary = summary.replace('âŒ', 'ğŸ¬')
            item['summary'] = summary

    def _build_items(self):
        res = []
        for i, item in enumerate(self._items):
            tmp = {}
            tmp['title'] = 'Episode ' + item['episode'] + ' | ' + item['title']
            tmp['link'] = item['url']
            tmp['guid'] = 'fanpie_' + re.search(r'\/([\_\-a-zA-Z0-9]*)\.mp3', item['url'])[1]
            tmp['pubDate'] = format_time(item['pub_date'])
            tmp['author'] = ', '.join(item['hosts'])
            tmp['enclosure'] = item['url']
            tmp['duration'] = item['duration']
            tmp['image'] = 'https://raw.githubusercontent.com/Reyshawn/FanpieFilmFeed/master/fanPie/assets/939x0w.jpg'
            tmp['description']= item['summary']
            res.append(tmp)
        return res

    def save(self, path):
        with open(path, 'w+') as f:
            json.dump(self._feed, f, ensure_ascii=False)

    def feed(self):
        return self._feed


def format_time(s):
    t = datetime.strptime(s, '%Y-%m-%d')
    t = t.replace(hour=17)
    return t.strftime("%a, %d %B %Y %H:%M:%S +0800")


if __name__ == "__main__":
    a = JsonParser('output.json', 'helper.rss')
    feed = a.feed()
    xml = FeedParser(feed)
    xml.save('fanPieFilm.rss')